{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages to use\n",
    "import twint\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Patches asyncio to allow the running of multiple event loops in Jupyter Notebooks.\n",
    "# Fixes: \"RuntimeError: This event loop is already running\"\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the distance between two lat/long coordinates\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    r = 6371\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) *   np.sin(delta_lambda / 2)**2\n",
    "    res = r * (2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a)))\n",
    "    return np.round(res, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Santa Coloma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSantaColomaTweets(start_date, end_date):\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Search Tweets with full municipal name 'Santa Coloma de Gramenet'\n",
    "    c = twint.Config()\n",
    "    c.Search = 'Santa Coloma de Gramenet'\n",
    "    c.Since = start_date\n",
    "    c.Until = end_date\n",
    "    c.Pandas = True\n",
    "    c.Hide_output = True\n",
    "    twint.run.Search(c)\n",
    "    \n",
    "    df = df.append(twint.storage.panda.Tweets_df)\n",
    "    \n",
    "    # Search Tweets with short municipal name 'Santa Coloma'\n",
    "    c = twint.Config()\n",
    "    c.Search = 'Santa Coloma'\n",
    "    c.Since = start_date\n",
    "    c.Until = end_date\n",
    "    c.Pandas = True\n",
    "    c.Hide_output = True\n",
    "    twint.run.Search(c)\n",
    "    \n",
    "    df = df.append(twint.storage.panda.Tweets_df)\n",
    "    df = df.drop_duplicates(subset=['id'], ignore_index=True)\n",
    "    \n",
    "    # Search Tweets with the various buildings and regions near Santa Coloma\n",
    "    c = twint.Config()\n",
    "    c.Search = '\\\"Rambla San Sebastian\\\" OR \\\"Fluvial del Besos\\\" OR \\\"Molinet\\\" OR \\\"Plaza del Rellotge\\\" OR \\\"Can Zam\\\" OR \\\"Can Peixauet\\\" OR \\\"Gran Sol\\\" OR \\\"Escuela Tanit\\\" OR \\\"Terra Roja\\\" OR \\\"Instituto Gassol\\\" OR \\\"CAP Santa Rosa\\\" OR \\\"Cinto Verdaguer\\\" OR \\\"del Fondo\\\"'\n",
    "    c.Since = start_date\n",
    "    c.Until = end_date\n",
    "    c.Pandas = True\n",
    "    c.Hide_output = True\n",
    "    twint.run.Search(c)\n",
    "    \n",
    "    df = df.append(twint.storage.panda.Tweets_df)\n",
    "    df = df.drop_duplicates(subset=['id'], ignore_index=True)\n",
    "    \n",
    "    # Search Tweets with location near 'Santa Coloma de Gramenet': North Side\n",
    "    c = twint.Config()\n",
    "    c.Geo = \"41.46287400801948, 2.2028934732857177, 1km\"\n",
    "    c.Since = start_date\n",
    "    c.Until = end_date\n",
    "    c.Pandas = True\n",
    "    c.Hide_output = True\n",
    "    twint.run.Search(c)\n",
    "    \n",
    "    df = df.append(twint.storage.panda.Tweets_df)\n",
    "    df = df.drop_duplicates(subset=['id'], ignore_index=True)\n",
    "    \n",
    "    # Search Tweets with location near 'Santa Coloma de Gramenet': South Side\n",
    "    c = twint.Config()\n",
    "    c.Geo = \"41.45039468429977, 2.212764002746006, 0.75km\"\n",
    "    c.Since = start_date\n",
    "    c.Until = end_date\n",
    "    c.Pandas = True\n",
    "    c.Hide_output = True\n",
    "    twint.run.Search(c)\n",
    "    \n",
    "    df = df.append(twint.storage.panda.Tweets_df)\n",
    "    df = df.drop_duplicates(subset=['id'], ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "data = getSantaColomaTweets(\"2019-07-15\", \"2019-07-24\") # effectively searches for dates 15-22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": [
    "# eliminate users posting in native language of area\n",
    "users = set(data.loc[~data['language'].isin(['es', 'ca', 'und'])]['username'])\n",
    "print(len(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "2\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "3\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "4\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "5\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "6\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "7\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "8\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "9\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "10\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "11\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "12\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "13\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "14\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "15\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "16\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "17\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "18\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "20\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "21\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "22\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "23\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "25\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "26\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "27\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "28\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "29\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "30\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "31\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "32\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "33\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "34\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "35\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "36\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "37\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "38\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "39\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "40\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "41\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "42\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "43\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "44\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "45\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "46\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "47\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "48\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "49\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "50\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "51\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "52\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "53\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "54\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "55\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "56\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "57\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "58\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "59\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "60\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "61\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "62\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "63\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "64\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "65\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "66\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "67\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "68\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "69\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "70\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "71\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "72\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "73\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "74\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "75\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "76\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "77\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "78\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "79\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "80\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "81\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "82\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "83\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "84\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "85\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "86\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "87\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "88\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "89\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "90\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "91\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "92\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "93\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "94\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "95\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "96\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "97\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "99\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "100\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "101\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "102\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "103\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "104\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "105\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "106\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "107\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "108\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "109\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "110\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "111\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "112\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "113\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "114\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "115\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "116\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "117\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "118\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "119\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "120\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "121\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "122\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "123\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "124\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "125\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "126\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "127\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "128\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "129\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "130\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "131\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "132\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "133\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "134\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "135\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "136\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "137\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "138\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "139\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "140\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "141\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "142\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "143\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "144\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "145\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "146\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "147\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "148\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "149\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "150\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "151\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "152\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "153\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "154\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "155\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "156\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "157\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "158\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "159\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "160\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "161\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "162\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "163\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "164\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "165\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "166\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "167\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "168\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "169\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "170\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "171\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "172\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "173\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "174\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "175\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "176\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "177\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "178\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "179\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "180\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "181\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "182\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "183\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "184\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "185\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "186\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "187\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "188\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "189\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "190\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "191\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "192\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "193\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "194\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "196\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "placelist = [x.lower() for x in [\"coloma\", \"Rambla San Sebastian\", \"Fluvial del Besos\", \"Molinet\", \"Plaza del Rellotge\", \"Can Zam\", \"Can Peixauet\", \"Gran Sol\", \"Escuela Tanit\", \"Terra Roja\", \"Instituto Gassol\", \"CAP Santa Rosa\", \"Cinto Verdaguer\", \"del Fondo\"]]\n",
    "pattern = '|'.join(placelist)\n",
    "\n",
    "less_than_two_weeks = []\n",
    "places = []\n",
    "i = 1\n",
    "\n",
    "# iterates through yearlong Tweets for the above selected users and filters users who have been associated with \n",
    "# Santa Coloma within 2 weeks \n",
    "for user in users:\n",
    "    print(i)\n",
    "    i += 1\n",
    "    c = twint.Config()\n",
    "    c.Username = user\n",
    "    c.Since = \"2019-01-01\"\n",
    "    c.Until = \"2019-12-31\"\n",
    "    c.Pandas = True\n",
    "    c.Hide_output = True\n",
    "    twint.run.Search(c)\n",
    "\n",
    "    df2 = twint.storage.panda.Tweets_df\n",
    "    if (len(df2) > 0): \n",
    "        df2['tweet'] = df2['tweet'].str.lower()\n",
    "        df2_tweets = df2[df2['tweet'].str.contains(pattern)]\n",
    "        df2_places = df2.loc[(df2['place'] != ''), ['username','place','date']]\n",
    "        \n",
    "\n",
    "        if len(df2_tweets) > 0:\n",
    "            max_date = datetime.strptime(max(df2_tweets['date']), \"%Y-%m-%d %H:%M:%S\")\n",
    "            min_date = datetime.strptime(min(df2_tweets['date']), \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            if max_date - min_date < timedelta(days=14):\n",
    "                less_than_two_weeks.append(user)\n",
    "        \n",
    "        if len(df2_places) > 0:\n",
    "            df2_places['coordinates'] = [x['coordinates'] for x in df2_places['place']]\n",
    "            # get distances to the two central points of Santa Coloma\n",
    "            df2_places['dist1'] = [haversine_distance(*x, 41.45039468429977, 2.212764002746006) for x in df2_places['coordinates']]\n",
    "            df2_places['dist2'] = [haversine_distance(*x, 41.46287400801948, 2.2028934732857177) for x in df2_places['coordinates']]\n",
    "            df2_places = df2_places[(df2_places['dist1'] < 0.75) | (df2_places['dist2'] < 1.0)]\n",
    "            \n",
    "            if len(df2_places) > 0:\n",
    "                max_date = datetime.strptime(max(df2_places['date']), \"%Y-%m-%d %H:%M:%S\")\n",
    "                min_date = datetime.strptime(min(df2_places['date']), \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "                if max_date - min_date < timedelta(days=14):\n",
    "                    places.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_users = {\"keyword_based\" : set(less_than_two_weeks), \"place_based\" : set(places)}\n",
    "\n",
    "pickle.dump( filtered_users, open( \"select_users.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ANFIA_it',\n",
       " 'AgenLucky303',\n",
       " 'AndorraSIR',\n",
       " 'AndreaMaggio76',\n",
       " 'Balestrantonio',\n",
       " 'BarcelonaBfr',\n",
       " 'BccBGB',\n",
       " 'BestOddsAlert',\n",
       " 'Bill30745412',\n",
       " 'BusinessIabw',\n",
       " 'Chris3890',\n",
       " 'DOVEEEEEE',\n",
       " 'FCBarcacom',\n",
       " 'FFerraioli',\n",
       " 'FisiTrentino',\n",
       " 'GioGuevara1975',\n",
       " 'GiomedMario',\n",
       " 'JoanSNTK',\n",
       " 'JuanWAS',\n",
       " 'LAMETALAge',\n",
       " 'LapsusRebersus',\n",
       " 'MLSZhivatalos',\n",
       " 'MMeneghetti1',\n",
       " 'MRNOBOD46774546',\n",
       " 'M_DePascalis',\n",
       " 'MaidenVojage',\n",
       " 'MariuszMachnik',\n",
       " 'MatiaSeguel',\n",
       " 'MightyTips',\n",
       " 'Nicola_Bressi',\n",
       " 'Nyctophile1_',\n",
       " 'ONA_Amianto',\n",
       " 'OVGroupSpA',\n",
       " 'OfficialMinis',\n",
       " 'P101Ventures',\n",
       " 'PenaEscalier6',\n",
       " 'Pinjamantunais1',\n",
       " 'Rapote',\n",
       " 'SalvoCap',\n",
       " 'Science_ofnoise',\n",
       " 'Scoty2hotty30',\n",
       " 'SebCochard_11',\n",
       " 'SergioAbramo',\n",
       " 'Sonofdl',\n",
       " 'Swim4life_it',\n",
       " 'SwimmerShopit',\n",
       " 'Tiziana008',\n",
       " 'URBANPETITALIA',\n",
       " '_Giusy__',\n",
       " '_kuball_',\n",
       " 'aagusrodriiguez',\n",
       " 'alanewsitaly',\n",
       " 'angelicaperezl',\n",
       " 'azzurridigloria',\n",
       " 'betpredictions_',\n",
       " 'brandobenifei',\n",
       " 'casciavitismo',\n",
       " 'cerelol',\n",
       " 'condeferran',\n",
       " 'corina_magno',\n",
       " 'cowboynando',\n",
       " 'daniluvhan1',\n",
       " 'dpl_news',\n",
       " 'elennaah__',\n",
       " 'emilianogriff78',\n",
       " 'enricospada2',\n",
       " 'erikamagl',\n",
       " 'frankrodIII',\n",
       " 'gianlia96',\n",
       " 'giuseppegalloIT',\n",
       " 'grissino78',\n",
       " 'hokigol',\n",
       " 'irish_CoffeeOF',\n",
       " 'kamalke30449656',\n",
       " 'lelewizpallotti',\n",
       " 'manderley69',\n",
       " 'maria_castromtz',\n",
       " 'merjmat_',\n",
       " 'mondialinet',\n",
       " 'nellygi824',\n",
       " 'neurophate_',\n",
       " 'ociciornia',\n",
       " 'oliverisindaco',\n",
       " 'pierolacorazza',\n",
       " 'piervi',\n",
       " 'pojetti',\n",
       " 'ptanona',\n",
       " 'rinorinorino',\n",
       " 'rumba_magica',\n",
       " 'sofi394',\n",
       " 'soniacasanovas',\n",
       " 'tralepagine',\n",
       " 'venioti',\n",
       " 'ziacarlacar'}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely_immigrant_users = set(less_than_two_weeks).union(set(places))\n",
    "likely_immigrant_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ANFIA_it',\n",
       " 'AgenLucky303',\n",
       " 'AndorraSIR',\n",
       " 'AndreaMaggio76',\n",
       " 'Balestrantonio',\n",
       " 'BarcelonaBfr',\n",
       " 'BccBGB',\n",
       " 'BestOddsAlert',\n",
       " 'Bill30745412',\n",
       " 'BusinessIabw',\n",
       " 'Chris3890',\n",
       " 'DOVEEEEEE',\n",
       " 'FCBarcacom',\n",
       " 'FFerraioli',\n",
       " 'FisiTrentino',\n",
       " 'GioGuevara1975',\n",
       " 'GiomedMario',\n",
       " 'JuanWAS',\n",
       " 'LAMETALAge',\n",
       " 'LapsusRebersus',\n",
       " 'MLSZhivatalos',\n",
       " 'MMeneghetti1',\n",
       " 'MRNOBOD46774546',\n",
       " 'M_DePascalis',\n",
       " 'MaidenVojage',\n",
       " 'MariuszMachnik',\n",
       " 'MatiaSeguel',\n",
       " 'MightyTips',\n",
       " 'Nicola_Bressi',\n",
       " 'Nyctophile1_',\n",
       " 'ONA_Amianto',\n",
       " 'OVGroupSpA',\n",
       " 'OfficialMinis',\n",
       " 'P101Ventures',\n",
       " 'PenaEscalier6',\n",
       " 'Pinjamantunais1',\n",
       " 'Rapote',\n",
       " 'SalvoCap',\n",
       " 'Science_ofnoise',\n",
       " 'Scoty2hotty30',\n",
       " 'SebCochard_11',\n",
       " 'SergioAbramo',\n",
       " 'Sonofdl',\n",
       " 'Swim4life_it',\n",
       " 'SwimmerShopit',\n",
       " 'Tiziana008',\n",
       " 'URBANPETITALIA',\n",
       " '_Giusy__',\n",
       " '_kuball_',\n",
       " 'aagusrodriiguez',\n",
       " 'alanewsitaly',\n",
       " 'angelicaperezl',\n",
       " 'azzurridigloria',\n",
       " 'betpredictions_',\n",
       " 'brandobenifei',\n",
       " 'casciavitismo',\n",
       " 'cerelol',\n",
       " 'condeferran',\n",
       " 'corina_magno',\n",
       " 'cowboynando',\n",
       " 'daniluvhan1',\n",
       " 'dpl_news',\n",
       " 'elennaah__',\n",
       " 'emilianogriff78',\n",
       " 'enricospada2',\n",
       " 'erikamagl',\n",
       " 'gianlia96',\n",
       " 'giuseppegalloIT',\n",
       " 'grissino78',\n",
       " 'hokigol',\n",
       " 'irish_CoffeeOF',\n",
       " 'kamalke30449656',\n",
       " 'lelewizpallotti',\n",
       " 'manderley69',\n",
       " 'maria_castromtz',\n",
       " 'merjmat_',\n",
       " 'mondialinet',\n",
       " 'nellygi824',\n",
       " 'neurophate_',\n",
       " 'ociciornia',\n",
       " 'oliverisindaco',\n",
       " 'pierolacorazza',\n",
       " 'piervi',\n",
       " 'pojetti',\n",
       " 'ptanona',\n",
       " 'rinorinorino',\n",
       " 'rumba_magica',\n",
       " 'sofi394',\n",
       " 'tralepagine',\n",
       " 'venioti',\n",
       " 'ziacarlacar'}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(less_than_two_weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JoanSNTK', 'LapsusRebersus', 'frankrodIII', 'soniacasanovas'}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(places)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
