{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "# Import packages to use\n",
    "import twint\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Patches asyncio to allow the running of multiple event loops in Jupyter Notebooks.\n",
    "# Fixes: \"RuntimeError: This event loop is already running\"\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLocationTweets(location_name):\n",
    "    c = twint.Config()\n",
    "    c.Search = location_name\n",
    "    c.Since = \"2019-01-01\"\n",
    "    c.Until = \"2019-12-31\"\n",
    "    c.Pandas = True\n",
    "    c.Hide_output = True\n",
    "    twint.run.Search(c)\n",
    "\n",
    "    return twint.storage.panda.Tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_santa_coloma = getLocationTweets('\\\"Santa Coloma de Gramenet\\\" OR \\\"Santa Coloma\\\" OR \\\"Rambla San Sebastian\\\"')\n",
    "pickle.dump(df_santa_coloma, open( \"df_santa_coloma.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_parque_fluvial = getLocationTweets('\\\"Parque Fluvial del Besos\\\" OR \\\"Parc Fluvial del Besos\\\" OR \\\"Fluvial del Besos\\\"')\n",
    "pickle.dump(df_parque_fluvial, open( \"df_parque_fluvial.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_parque_molinet = getLocationTweets('\\\"Parque Molinet\\\" OR \\\"Parc Molinet\\\" OR \\\"Molinet\\\"')\n",
    "pickle.dump(df_parque_molinet, open( \"df_parque_molinet.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_plaza_rellotge = getLocationTweets('\\\"Plaza del Rellotge\\\" OR \\\"Pla√ßa del Rellotge\\\"')\n",
    "pickle.dump(df_plaza_rellotge, open( \"df_plaza_rellotge.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_parque_can_zam = getLocationTweets('\\\"Parque Can Zam\\\" OR \\\"Parc Can Zam\\\" OR \\\"Can Zam\\\"')\n",
    "pickle.dump(df_parque_can_zam, open( \"df_parque_can_zam.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_instituto_can_peixauet = getLocationTweets('\\\"Instituto Can Peixauet\\\" OR \\\"Institut Can Peixauet\\\" OR \\\"Can Peixauet\\\"')\n",
    "pickle.dump(df_instituto_can_peixauet, open( \"df_instituto_can_peixauet.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_parque_gran_sol = getLocationTweets('\\\"Parque Gran Sol\\\" OR \\\"Parc Gran Sol\\\" OR \\\"Gran Sol\\\"')\n",
    "pickle.dump(df_parque_gran_sol, open( \"df_parque_gran_sol.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_escuela_tanit = getLocationTweets('\\\"Escuela Tanit\\\" OR \\\"Escola Tanit\\\"')\n",
    "pickle.dump(df_escuela_tanit, open( \"df_escuela_tanit.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_instituto_terra_roja = getLocationTweets('\\\"Instituto Terra Roja\\\" OR \\\"Institut Terra Roja\\\" OR \\\"Terra Roja\\\"')\n",
    "pickle.dump(df_instituto_terra_roja, open( \"df_instituto_terra_roja.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_instituto_gassol = getLocationTweets('\\\"Instituto Gassol\\\" OR \\\"Institut Gassol\\\"')\n",
    "pickle.dump(df_instituto_gassol, open( \"df_instituto_gassol.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_CAP = getLocationTweets('\\\"CAP Santa Rosa\\\"')\n",
    "pickle.dump(df_CAP, open( \"df_CAP.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_del_fondo = getLocationTweets('\\\"Mercado del Fondo\\\" OR \\\"Mercat del Fondo\\\" OR \\\"del Fondo\\\"')\n",
    "pickle.dump(df_del_fondo, open( \"df_del_fondo.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_cinto = getLocationTweets('\\\"Cinto Verdaguer\\\"')\n",
    "pickle.dump(df_cinto, open( \"df_cinto\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n"
     ]
    }
   ],
   "source": [
    "df_nus_trinitat = getLocationTweets('\\\"Nus de la Trinitat\\\"')\n",
    "pickle.dump(df_nus_trinitat, open( \"df_nus_trinitat\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeTimezone(df):\n",
    "    df[\"times\"] = df[\"date\"] + ex[\"timezone\"]\n",
    "    df[\"times\"] = pd.to_datetime(ex[\"times\"], format=\"%Y-%m-%d %H:%M:%S%z\")\n",
    "    df[\"times\"] = df[\"times\"].dt.tz_convert(\"Europe/Madrid\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStats(df):\n",
    "    stats = dict()\n",
    "    sample_size = len(df)\n",
    "    \n",
    "    stats[\"size\"] = sample_size\n",
    "    lang_counts = Counter(df[\"language\"])\n",
    "    for k,v in lang_counts.items():\n",
    "        proportion = v / sample_size\n",
    "        raw_and_proportion = str(v) + \" \" + str(proportion)\n",
    "        lang_counts[k] = raw_and_proportion\n",
    "    stats[\"language\"] = dict(lang_counts)\n",
    "    \n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LizRiver530</td>\n",
       "      <td>@Nestorosp üòÜ eso salio del fondo de tu coraz√≥n...</td>\n",
       "      <td>1211436548408979458</td>\n",
       "      <td>2019-12-29 18:59:15</td>\n",
       "      <td>-0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jerrydady</td>\n",
       "      <td>@mario_dico50 Pero si ahorraron 290 MMDP seg√∫n...</td>\n",
       "      <td>1211436296989790209</td>\n",
       "      <td>2019-12-29 18:58:15</td>\n",
       "      <td>-0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NicoAL1901</td>\n",
       "      <td>@Rdiego05 @ppenalozal @kioshikubo1924 @JeanMis...</td>\n",
       "      <td>1211436082874765313</td>\n",
       "      <td>2019-12-29 18:57:24</td>\n",
       "      <td>-0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Presyisoff</td>\n",
       "      <td>@SuckMyKhezu Te iba a preguntar qui√©n era ese ...</td>\n",
       "      <td>1211435985818529792</td>\n",
       "      <td>2019-12-29 18:57:01</td>\n",
       "      <td>-0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elsoldepuebla1</td>\n",
       "      <td>#√öLTIMAHORA Rescatan a hombre del fondo de bar...</td>\n",
       "      <td>1211435478781550592</td>\n",
       "      <td>2019-12-29 18:55:00</td>\n",
       "      <td>-0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         username                                              tweet  \\\n",
       "0     LizRiver530  @Nestorosp üòÜ eso salio del fondo de tu coraz√≥n...   \n",
       "1       Jerrydady  @mario_dico50 Pero si ahorraron 290 MMDP seg√∫n...   \n",
       "2      NicoAL1901  @Rdiego05 @ppenalozal @kioshikubo1924 @JeanMis...   \n",
       "3      Presyisoff  @SuckMyKhezu Te iba a preguntar qui√©n era ese ...   \n",
       "4  elsoldepuebla1  #√öLTIMAHORA Rescatan a hombre del fondo de bar...   \n",
       "\n",
       "                    id                 date timezone  \n",
       "0  1211436548408979458  2019-12-29 18:59:15    -0500  \n",
       "1  1211436296989790209  2019-12-29 18:58:15    -0500  \n",
       "2  1211436082874765313  2019-12-29 18:57:24    -0500  \n",
       "3  1211435985818529792  2019-12-29 18:57:01    -0500  \n",
       "4  1211435478781550592  2019-12-29 18:55:00    -0500  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_del_fondo[[\"username\", \"tweet\", \"id\", \"date\", \"timezone\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
